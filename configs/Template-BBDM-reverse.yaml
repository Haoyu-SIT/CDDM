# Brownian Bridge Diffusion Model Template(Pixel Space)
runner: "BBDMRunner"
training:
  n_epochs: 120
  n_steps: 400000
  save_interval: 2
  sample_interval: 2
  validation_interval: 2
  accumulate_grad_batches: 1

testing:
  clip_denoised: False
  sample_num: 5

data:
  dataset_name: '2009'
  dataset_type: 'Rainfall_aligned'
  dataset_config:
    access_dir: '/scratch/iu60/hs2870/AGCD_BIG'
    awap_dir: '/scratch/iu60/hs2870/Processed_data_BIG'
    start_date: '20090101'
    end_date: '20091230'
    leading_time_we_use: [1,6]
    target_size: [128,128] #别忘了改unet图片大小
    channels: 3
  train:
    batch_size: 8
    shuffle: True
  val:
    batch_size: 8
    shuffle: True
  test:
    batch_size: 8
    shuffle: False

model:
  model_name: "BrownianBridge" # part of result path
  model_type: "BBDM" # specify a module
  latent_before_quant_conv: False
  normalize_latent: False
  only_load_latent_mean_std: False
  # model_load_path:  # model checkpoint path
  # optim_sche_load_path:  # optimizer scheduler checkpoint path

  EMA:
    use_ema: True
    ema_decay: 0.995
    update_ema_interval: 8 # step
    start_ema_step: 30000

  CondStageParams:
    n_stages: 2
    in_channels: 3
    out_channels: 3

  BB:
    optimizer:
      weight_decay: 0.0001
      optimizer: 'Adam'
      lr: 1.e-5
      beta1: 0.9

    lr_scheduler:
      factor: 0.5
      patience: 30
      threshold: 0.0001
      cooldown: 3000
      min_lr: 5.e-7

    params:
      mt_type: 'linear' # options {'linear', 'sin'}
      objective: 'grad' # options {'grad', 'noise', 'ysubx'}
      loss_type: 'l1+relative 0.4' # options {'l1', 'l2'}
      # options {'l1', 'l2','huber','relative Bias','crps_loss'}

      skip_sample: True
      sample_type: 'linear' # options {"linear", "sin"}
      sample_step: 400

      num_timesteps: 20000 # timesteps
      eta: 0.1 # DDIM reverse process eta
      max_var: 0.5 # maximum variance

      UNetParams:
        image_size: 128
        in_channels: 6
        model_channels: 128
        out_channels: 3
        num_res_blocks: 4
        attention_resolutions: !!python/tuple
          - 32
          - 16
          - 8
        channel_mult: !!python/tuple
          - 1
          - 4
          - 8
        conv_resample: True
        dims: 2
        num_heads: 8
        num_head_channels: 64
        use_scale_shift_norm: True
        resblock_updown: True
        use_spatial_transformer: False
        context_dim:
        condition_key: "first_stage" # options {"SpatialRescaler", "first_stage", "nocond"}